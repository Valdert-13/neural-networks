{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from keras.datasets import imdb\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words = 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((25000,), (25000,))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape, train_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((25000,), (25000,))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.shape, test_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#подгружаем индексы\n",
    "word_index = imdb.get_word_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Делаем реверс словаря, индеск становится ключем - слово значением\n",
    "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNK at the height of the UNK big UNK racism row in 2007 involving UNK UNK and the late UNK UNK i condemned on an internet forum those UNK b b ' fans who praised the show after years of bashing UNK UNK sitcoms such as UNK UNK UNK UNK UNK i thought they were being UNK and said so UNK ain't half hot UNK was then thrown into the argument with some pointing out it had starred an english actor UNK up well yes but michael bates had lived in india as a boy and spoke UNK UNK the show's UNK overlook the reality he brought to his performance as UNK UNK UNK the noted indian character actor UNK UNK said in a 1995 documentary UNK UNK the UNK that he was upset when he heard bates had landed the role but added no indian actor could have played that role as well as bates indeed br br UNK was perry and UNK companion show to UNK UNK also set in wartime the UNK english town of UNK on sea had been replaced by the hot steamy UNK of india in particularly a place called UNK where an army concert party puts on shows for the troops among them UNK UNK george UNK his first sitcom role since UNK in UNK camp UNK UNK UNK melvyn hayes UNK UNK UNK UNK UNK de UNK UNK graham john UNK and UNK UNK the late christopher mitchell UNK over this gang of UNK was the UNK sergeant major williams the brilliant UNK davies who regarded them all as UNK his frustration at not being able to lead his men up the jungle to engage the enemy in combat made him bitter and bullying though he was nice to UNK whom he thought was his UNK son then there was ever so english colonel reynolds donald UNK and UNK captain UNK michael UNK UNK was like a wise old UNK beginning each show by talking to the camera and closing them by UNK obscure UNK UNK he loved being UNK so much he came to regard himself as practically british his friends were the tea making UNK UNK the late UNK UNK who went on to UNK your UNK and the rope pulling UNK UNK UNK UNK so real indians featured in the show another point its UNK ignore UNK also provided what was described on the credits as UNK UNK similar to the UNK songs used as incidental music on UNK UNK each edition closed with him UNK UNK of hope UNK only to be UNK by a UNK up ' from williams the excellent opening theme was penned by jimmy perry and derek UNK br br though never quite UNK UNK UNK in the UNK affections UNK nevertheless was popular enough to run for a total of eight seasons in 1975 davies and UNK topped the UNK with a cover version of that old UNK UNK UNK they then recorded an entire album of old UNK entitled what else UNK UNK ' br br the show hit crisis point three years later when bates died of cancer rather than UNK the role of UNK the writers just let him be quietly forgotten when george UNK left the character of UNK took his place as UNK providing another source of comedy br br the last edition in 1981 saw the soldiers leave india by boat for UNK the UNK UNK watching them go with great sadness as did viewers br br repeats have been few and far between mainly on u k gold all because of its so called UNK reputation this is strange for one thing the show was not specifically about racism if a white man UNK up is so wrong why does david UNK 1984 film 'a passage to UNK still get shown on television it featured alec guinness as an indian and won two oscars it was derived from jimmy UNK own experiences some characters were based on real people the sergeant major really did refer to his men as UNK i take the view that if you are going to put history on television get it right UNK the past no matter how UNK it might seem to modern audiences is UNK UNK UNK was both funny and truthful and viewers saw this thank heavens for d v d 's i say time to stop this review as williams would say i'll have no UNK in this jungle\n"
     ]
    }
   ],
   "source": [
    "# Проверяем что получилось\n",
    "decoded_review = ' '.join([reverse_word_index.get(i - 3, 'UNK') for i in train_data[17]])\n",
    "print(decoded_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9999\n"
     ]
    }
   ],
   "source": [
    "print(max([max(review) for review in train_data]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(min([min(review) for review in train_data]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создание 0 матрицы\n",
    "def vectorize_sequences(sequences, dimension=10000):\n",
    "    results = np.zeros((len(sequences), dimension), dtype=np.float32)\n",
    "    for i, sequence in enumerate(sequences):\n",
    "        results[i, sequence] = 1.\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = vectorize_sequences(train_data)\n",
    "test_data = vectorize_sequences(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 10000)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = np.reshape(np.asarray(train_labels, dtype=np.float32), (len(train_data), 1))\n",
    "test_labels = np.reshape(np.asarray(test_labels, dtype=np.float32), (len(test_data), 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model.\n",
    "model = Sequential([\n",
    "  Dense(1024, activation='relu', input_shape=(10000,)),\n",
    "  Dense(256, activation='relu'),    \n",
    "#  Dense(64, activation='relu'),\n",
    "  Dense(2, activation='softmax'),\n",
    "])\n",
    "\n",
    "# Compile the model.\n",
    "\n",
    "model.compile(\n",
    "  optimizer='rmsprop',\n",
    "  loss='binary_crossentropy',\n",
    "  metrics=['acc'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 7\n",
    "batch_size = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n",
      "25000/25000 [==============================] - 1s 54us/step - loss: 0.4960 - acc: 0.7785\n",
      "Epoch 2/7\n",
      "25000/25000 [==============================] - 1s 43us/step - loss: 0.2335 - acc: 0.9062\n",
      "Epoch 3/7\n",
      "25000/25000 [==============================] - 1s 43us/step - loss: 0.1300 - acc: 0.9508\n",
      "Epoch 4/7\n",
      "25000/25000 [==============================] - 1s 43us/step - loss: 0.0728 - acc: 0.9793\n",
      "Epoch 5/7\n",
      "25000/25000 [==============================] - 1s 43us/step - loss: 0.0767 - acc: 0.9832\n",
      "Epoch 6/7\n",
      "25000/25000 [==============================] - 1s 43us/step - loss: 0.0016 - acc: 0.9999\n",
      "Epoch 7/7\n",
      "25000/25000 [==============================] - 1s 44us/step - loss: 1.1633e-04 - acc: 1.0000\n",
      "25000/25000 [==============================] - 2s 62us/step\n",
      "Test accuracy: 0.88\n"
     ]
    }
   ],
   "source": [
    "# Train the model.\n",
    "model.fit(\n",
    "  train_data,\n",
    "  to_categorical(train_labels),\n",
    "  epochs=epochs,\n",
    "  batch_size = batch_size,\n",
    ")\n",
    "\n",
    "# Evaluate the model.\n",
    "loss, accuracy = model.evaluate(\n",
    "  test_data,\n",
    "  to_categorical(test_labels)\n",
    ")\n",
    "\n",
    "# Save the model to disk.\n",
    "model.save_weights('model.h5')\n",
    "\n",
    "print('Test accuracy: %.2f' % (accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
